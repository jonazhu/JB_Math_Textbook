{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9118689e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f834e7",
   "metadata": {},
   "source": [
    "# JNB Lab: Calculus of Entropy in Daily Life"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33f328",
   "metadata": {},
   "source": [
    "The goal of this lab is to explore how calculus cam be used to explore the concept of entropy as might be useful within "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7285e",
   "metadata": {},
   "source": [
    "## 1. Derivative Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d90012",
   "metadata": {},
   "source": [
    "Given a function $y=f(x)$, the derivative $f'(x)$ evalauted at $x=a$ gives us the slope of the tangent (instantaneous rate of change)  to the graph of $y=f(x)$ ad the point $(a,f(a))$.  Maximum and minimum points are special since the tangents are horitzontal at those points and hence the derivative satisfies the equation $f'(x)=0$. Maximum and minimum points are important in applications since, for example, minimizing cost or maximizing benefit of a project is often a primary goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013495a",
   "metadata": {},
   "source": [
    "Entropy is an important example discussed in the section on societal applications in the final chapter (complex systems) of this book. We illustrate here why minimization/maximazation of entropy is important.  Suppose you have  a committee  of $N$ people voting on a certain decision such that a proportion $p_1=p$ strongly prefers option A and a proportion $p_2=1-p$ strongly prefers option B .  Note that there is no disagreement  if $p_1=1$ and $p_2=0$ (everyone strongly prefers option A) and likewise there is no disagreement  if $p_1=0$ and $p_2=1$ (everyone strongly prefers option B.)  Note that if $p_1=.9$ and $p_2=.1$, there is a strong consensus for Option A so while there is a little bit of disagreement, Option A will likely carry.  Note that the case where the population is evely split $p_1=p_2=.5$ will have the greatest disagreement  in trying to achieve a consensus. \n",
    "\n",
    "\n",
    "Entropy can be used to measure the level of disagreement.  we define the Shannon entropy as\n",
    "\n",
    "$$\n",
    "H(p) = -\\sum_{i=1}^2 p_i \\ln p_i = -[p\\ln p + (1-p)\\ln(1-p)].\n",
    "$$\n",
    "\n",
    "where $0\\le p \\le 1$.  Exercise 1.1 shows the properties of this function $H(p)$ correspond to the amount of disagreement in our example.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee6e85",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657a62e",
   "metadata": {},
   "source": [
    "```{admonition} Exercises\n",
    "\n",
    "<b>1.1</b>\n",
    "\n",
    "a) Make a plot of $H(p)= -[p\\ln p + (1-p)\\ln(1-p)]$ on the interval $0<p<1$\n",
    "\n",
    "b) Use L'Hopital's rule to evaluate the one-sided limits $H(0)=\\lim_{p\\rightarrow 0^+} H(p)$ and $H(1)=\\lim_{p\\rightarrow 1^-} H(p)$.\n",
    "\n",
    "c) Use calculus to prove that a maximum value of $H(p)$ occurs at $p=.5$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d300e09",
   "metadata": {},
   "source": [
    "## 2. Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b9f5b",
   "metadata": {},
   "source": [
    "Suppose now there are $k$ options.  $p_i$ is the proportion of committee members favoring option  $i$ ($1\\le i \\le k$ and $p_1+....+p_k=1$).\n",
    "\n",
    "$$\n",
    "H= -\\sum_{i=1}^k p_i \\ln p_i= -(p_1\\ln p_1 + p_2\\ln p_2 + ... + p_k \\ln p_k).\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b22d6",
   "metadata": {},
   "source": [
    "### Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf56ce8",
   "metadata": {},
   "source": [
    "```{admonition} Exercises\n",
    "<b>2.1</b>\n",
    "\n",
    "1. Consider the case with $k=3$. Compute the entropy $H$ if \n",
    "\n",
    "a) $p_1=.5, p_2=.3, p_3=.2$ and \n",
    "\n",
    "b) $p_1=.2, p_2=.5, p_3=.3$ \n",
    "\n",
    "c) $p_1=.2, p_2=.3, p_3=.5$ \n",
    "\n",
    "2. What does problem 1 tell us about the computation of entropy of disagreement?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1969407",
   "metadata": {},
   "source": [
    "## 3. Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ee172",
   "metadata": {},
   "source": [
    "Now let us consider a situation where you are holding a dinner and there is a certain probability $p_k$ that a guest prefers to arrive between $k$ and $k+1$ hours late.  If all guests prefer to arrive no more than say 1/2 hour late, then $p_0=1$ and all other $p_k=0$, so the entropy $H=0$. This is in certain cultures an ideal situation and there is no major disagreement in the preferred arrival time ($H=0$).\n",
    "\n",
    "In other cases, it might be normative for guests to arrive substantially later than the announced time.  For example, if all guests prefer to arrive between $k=1$ and $k=2$ (between 1 and 2 hours late), then $p_1=1$ and again there is no major disagreement ($H=0$).\n",
    "\n",
    "\n",
    "We can use a probability distribution to model the probability of a preferred arrival time.  For example, if the mean arrival time is 10 minutes after the designated time (1/k=1/6 hour), then we consider the probability density function  $f(x)=\\frac{1}{6} e^{-6x}$ where $x\\in[0,\\infty)$.  The probability that a guest arrives in the interval $k\\le x \\le k+1$ is given by the definite integral\n",
    "\n",
    "$$\n",
    "p_k=prob(k\\le x \\le k+1) = \\int_k^{k+1} f(x)\\, dx = (1/6) \\int_k^{k+1} e^{-6x}\\,dx= -\\frac{1}{36} e^{-6x} \\mid_k^{k+1} = -\\frac{1}{36}[e^{-6(k+1)}-e^{-6k}]. $$\n",
    "\n",
    "For example, $p_0= - \\frac{1}{36}[ e^{-6} -1] \\approx .9999 $   \n",
    "\n",
    "and  \n",
    "\n",
    "$p_1=- \\frac{1}{36}[ e^{-6(2)} -exp(-6)] \\approx .0001$\n",
    "\n",
    "so\n",
    "\n",
    "$H\\approx .001$.  (There is almost no disagreement in preferred arrival time.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4956a6",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8fc94",
   "metadata": {},
   "source": [
    "```{admonition} Exercise\n",
    "<b>3.1</b> An exponential distribution has the form $f(x)=ke^{-kx}$ where $k>0$ and $0\\le x < \\infty$.\n",
    "\n",
    "a) Show that $prob(0\\le x < \\infty) = 1$.\n",
    "\n",
    "b) Given a continuous probability distribution $f(x)$ for $x\\in I$, the mean is computed as $\\int_{x\\in I} x f(x)\\, dx$. Find the mean for the exponential distribution in terms of $k$\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b93b14",
   "metadata": {},
   "source": [
    "## 4. Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b52ba2",
   "metadata": {},
   "source": [
    "Let us consider the context of teaching a class of math students with a random variable $X$ denoting a standardized entrance test score. If $X<0$, the score is below average, and if $X>0, the score is above average.  Note that if all students are average, teaching the class is simpler than if there is a big spread in the students' range of ability. Entropy in this case is interpreted in this case to mean complexity. \n",
    "\n",
    "Here we would like to compare two distributions with domain $-\\infty x \\infty$:\n",
    "\n",
    "$f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2}$ (standard unit normal distribution)\n",
    "\n",
    "$g(x) = \\frac{1}{\\pi} \\frac{1}{1+x^2}$ (Cauchy distribution)\n",
    "\n",
    "In particular, we would like to compare the contribution to the complexity (entropy) for the tails $x<-3$ and $x>3$.\n",
    "We will classify students as 'usual' if $-3\\le X \\le 3$ and `exceptional' if $x>3$ or $X<-3$.\n",
    "\n",
    "In practical terms, we are asking how the complexity is impacted by very strong or very weak students for these two distributions.  \n",
    "\n",
    "Intuitively we know for a normal distribution, there is only a .3\\% chance of being more than 3 standard deviations above or below the mean.  So for a class, say of 10 students, we would expect .03 students to be exceptional. So there would be eseentially no contribution to the complexity from a \n",
    "\n",
    "On the other hand, for a Cauchy distribution the probability is .2 to get a very strong or a very weak student, and so the for a class of 10 students, we would expect to see 2 exceptional students.  The contribution to complexity is $H_{tail} = -.2 ln (.2)\\approx .1$.\n",
    "\n",
    "\n",
    "To estimate the complexity of a normally distributed vs. Cauchy distributed class, we can use a Monte Carlo simulation.\n",
    "That is, we draw a sample of 10 random values, determine the proportion of usual and exceptional students, and compute the entropy. We illustrate this for a routine class (normally distributed) and ask you to do the analysis of a Cauchy distributed class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558aaec1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of Normal Class= 0.00879732781927398\n",
      "Contribution to Entropy by Exceptional Students= 0.006221442622110208\n"
     ]
    }
   ],
   "source": [
    "trials=10000\n",
    "class_size=10\n",
    "s = np.random.standard_normal(trials*class_size)\n",
    "\n",
    "Hroutine=[]\n",
    "Hexceptional=[]\n",
    "Hsum=[]\n",
    "k=0\n",
    "\n",
    "for j in np.arange(0,trials,1):\n",
    "    routine=0\n",
    "    exceptional=0\n",
    "    for i in np.arange(0,10,1):   \n",
    "        if s[k]>3 or s[k]<-3:\n",
    "            exceptional=exceptional+1\n",
    "            k=k+1\n",
    "        else: \n",
    "            routine=routine+1\n",
    "            k=k+1\n",
    "    if routine>0:\n",
    "        p=routine/10\n",
    "        Hroutine.append(-p*np.log(p))\n",
    "    else:\n",
    "        Hroutine.append(0)\n",
    "    if exceptional>0:\n",
    "        p=exceptional/10\n",
    "        Hexceptional.append(-p*np.log(p))\n",
    "    else:\n",
    "        Hexceptional.append(0)\n",
    "    Hsum.append(Hroutine[j]+Hexceptional[j])\n",
    "        \n",
    "H=np.mean(Hsum)\n",
    "Hex=np.mean(Hexceptional)\n",
    "\n",
    "print(\"Entropy of Normal Class=\", H)  \n",
    "print(\"Contribution to Entropy by Exceptional Students=\", Hex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d843821",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc623be",
   "metadata": {},
   "source": [
    "```{admonition} Exercise\n",
    "\n",
    "a) Sketch the unit normal and Cauchy distributions on the interval $-5\\le x \\le 5$. What do you note about the tails of these distributions?\n",
    "\n",
    "b) Do a Monte Carlo simulation with 10,000 trials to estimate the entropy of a Cauchy distributed class with 10 students as well as the contribution to the entropy by exceptional students.\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
